{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import GASF, GADF\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stockFileNames=os.listdir('./Stocks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!\n"
     ]
    }
   ],
   "source": [
    "stockSymbol=[]\n",
    "col_names=['Date','Open','High','Low','Close','Volume','c']\n",
    "dataList=list()\n",
    "for f in stockFileNames:\n",
    "    symbol=[str.upper(f.split('.')[0])]\n",
    "    fileName='./Stocks/'+f\n",
    "    fp=open(fileName,'r')\n",
    "    if len(fp.read())>0:\n",
    "        data=np.array(pd.read_csv(fileName,header=None))\n",
    "        for d in data[1:]:\n",
    "            dataList.append(d)\n",
    "            stockSymbol.append(symbol)\n",
    "        \n",
    "    fp.close()\n",
    "print('DONE!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14887665, 7), (14887665, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataList),np.shape(stockSymbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(dataList,columns=col_names)\n",
    "df2=pd.DataFrame(stockSymbol,columns=['SYMBOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2017-01-03\n",
       "1    2017-01-04\n",
       "2    2017-01-05\n",
       "3    2017-01-06\n",
       "4    2017-01-09\n",
       "5    2017-01-10\n",
       "6    2017-01-11\n",
       "7    2017-01-12\n",
       "8    2017-01-13\n",
       "9    2017-01-17\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllSymbolList=np.unique(df2)\n",
    "df=pd.concat([df1,df2],axis=1)\n",
    "df.head(5)\n",
    "df['Date'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>24.692</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>25.026</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>24.849</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>24.781</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>24.572</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Close SYMBOL\n",
       "0  2017-01-03  24.692   OUSM\n",
       "1  2017-01-04  25.026   OUSM\n",
       "2  2017-01-05  24.849   OUSM\n",
       "3  2017-01-06  24.781   OUSM\n",
       "4  2017-01-09  24.572   OUSM"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCloseDF=df[['Date','Close','SYMBOL']]\n",
    "allCloseDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13849"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCloseDataFromSymbols(df,symbol_list):\n",
    "    return df[df['SYMBOL'].isin(symbol_list)][['Date','Close']]\n",
    "\n",
    "resultDF=getCloseDataFromSymbols(allCloseDF,['AMZN','FB','GOOGL','NFLX', 'AMZA' ])\n",
    "len(resultDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>c</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>24.88</td>\n",
       "      <td>24.88</td>\n",
       "      <td>24.568</td>\n",
       "      <td>24.692</td>\n",
       "      <td>12957</td>\n",
       "      <td>0</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>24.732</td>\n",
       "      <td>25.944</td>\n",
       "      <td>24.732</td>\n",
       "      <td>25.026</td>\n",
       "      <td>10840</td>\n",
       "      <td>0</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>25.874</td>\n",
       "      <td>25.874</td>\n",
       "      <td>24.8</td>\n",
       "      <td>24.849</td>\n",
       "      <td>13104</td>\n",
       "      <td>0</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>24.82</td>\n",
       "      <td>24.858</td>\n",
       "      <td>24.771</td>\n",
       "      <td>24.781</td>\n",
       "      <td>2069</td>\n",
       "      <td>0</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>24.79</td>\n",
       "      <td>24.79</td>\n",
       "      <td>24.572</td>\n",
       "      <td>24.572</td>\n",
       "      <td>17870</td>\n",
       "      <td>0</td>\n",
       "      <td>OUSM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close Volume  c SYMBOL\n",
       "0  2017-01-03   24.88   24.88  24.568  24.692  12957  0   OUSM\n",
       "1  2017-01-04  24.732  25.944  24.732  25.026  10840  0   OUSM\n",
       "2  2017-01-05  25.874  25.874    24.8  24.849  13104  0   OUSM\n",
       "3  2017-01-06   24.82  24.858  24.771  24.781   2069  0   OUSM\n",
       "4  2017-01-09   24.79   24.79  24.572  24.572  17870  0   OUSM"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllSymbolList=np.unique(df2)\n",
    "df=pd.concat([df1,df2],axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from random import shuffle\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "def getPastSequenceData(df,window):\n",
    "    #df=np.array(df)\n",
    "    X=[]\n",
    "    y=[]\n",
    "    p = scaler.fit_transform(np.array(df['Close']).reshape(-1,1)) \n",
    "    #shuffle(p)\n",
    "    for i in range(1,len(df)-window,window):\n",
    "        #print(df[i-1:i+window-1],df[i+window-1])\n",
    "        date=df['Date'].iloc[i]\n",
    "        date=date.replace('-','')\n",
    "        #print(date)\n",
    "        date=np.array(date)\n",
    "        vals=np.array(p[i-1:i+window-1])\n",
    "        temp=vals\n",
    "        X.append(temp)\n",
    "        y.append(p[i+window-1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13849, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karimmady/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1730, 8, 1), (1730, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resultDF = scaler.fit_transform(resultDF)\n",
    "print (resultDF.shape)\n",
    "\n",
    "X,y=getPastSequenceData(resultDF,8)\n",
    "X=np.array(X)\n",
    "\n",
    "X=X.reshape(X.shape[0],X.shape[1],1)\n",
    "y=np.array(y)\n",
    "np.shape(X),np.shape(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01187533]\n",
      " [0.01202732]\n",
      " [0.01200788]\n",
      " ...\n",
      " [0.22220946]\n",
      " [0.20837052]\n",
      " [0.18442192]]\n",
      "(8, 1)\n",
      "(1442, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "tsSplit=TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "for train_index,test_index in tsSplit.split(X):\n",
    "    X_train, X_test = X[:len(train_index)], X[len(train_index): (len(train_index)+len(test_index))]\n",
    "    y_train, y_test = y[:len(train_index)], y[len(train_index): (len(train_index)+len(test_index))]\n",
    "\n",
    "\n",
    "print (y_train)\n",
    "print (X_train.shape[1:])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_35 (Conv1D)           (None, 9, 32)             128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 9, 32)             3104      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 3, 64)             6208      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 3, 64)             12352     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 219,425\n",
      "Trainable params: 219,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 8, 32)             96        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 8, 32)             2080      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 30)                5670      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 200)               6200      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 24,147\n",
      "Trainable params: 24,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.692904, acc: 0.509362]  [A loss: 0.672302, acc: 0.975728]\n",
      "1: [D loss: 0.709112, acc: 0.500000]  [A loss: 0.665392, acc: 0.995146]\n",
      "2: [D loss: 0.712637, acc: 0.500000]  [A loss: 0.650478, acc: 0.999306]\n",
      "3: [D loss: 0.720763, acc: 0.500000]  [A loss: 0.633920, acc: 1.000000]\n",
      "4: [D loss: 0.734772, acc: 0.500000]  [A loss: 0.609107, acc: 1.000000]\n",
      "5: [D loss: 0.747677, acc: 0.500000]  [A loss: 0.588806, acc: 1.000000]\n",
      "6: [D loss: 0.766205, acc: 0.500000]  [A loss: 0.566222, acc: 1.000000]\n",
      "7: [D loss: 0.790678, acc: 0.500000]  [A loss: 0.538226, acc: 1.000000]\n",
      "8: [D loss: 0.830402, acc: 0.500000]  [A loss: 0.505097, acc: 1.000000]\n",
      "9: [D loss: 0.881190, acc: 0.500000]  [A loss: 0.466626, acc: 1.000000]\n",
      "0: [D loss: 0.793788, acc: 0.500000]  [A loss: 0.389390, acc: 1.000000]\n",
      "1: [D loss: 0.785154, acc: 0.500000]  [A loss: 0.296678, acc: 1.000000]\n",
      "2: [D loss: 0.780877, acc: 0.500000]  [A loss: 0.196267, acc: 1.000000]\n",
      "3: [D loss: 0.776593, acc: 0.500000]  [A loss: 0.109000, acc: 1.000000]\n",
      "4: [D loss: 0.779243, acc: 0.500000]  [A loss: 0.049487, acc: 1.000000]\n",
      "5: [D loss: 0.769784, acc: 0.500000]  [A loss: 0.017514, acc: 1.000000]\n",
      "6: [D loss: 0.736496, acc: 0.500000]  [A loss: 0.005345, acc: 1.000000]\n",
      "7: [D loss: 0.663751, acc: 0.500000]  [A loss: 0.001854, acc: 1.000000]\n",
      "8: [D loss: 0.560186, acc: 0.500347]  [A loss: 0.000510, acc: 1.000000]\n",
      "9: [D loss: 0.440787, acc: 0.595354]  [A loss: 0.000200, acc: 1.000000]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, AveragePooling1D, MaxPooling1D\n",
    "from keras.layers import Conv1D, Conv2DTranspose, UpSampling2D, GRU\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization, Concatenate, Reshape\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (Wâˆ’F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.2\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        Input_shape = (9,1)\n",
    "        self.D.add(Conv1D(32, 3, padding='same', input_shape = Input_shape))\n",
    "        self.D.add(Activation('elu'))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv1D(32, 3, padding='same'))\n",
    "        self.D.add(Activation('elu'))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        self.D.add(MaxPooling1D(pool_size=3))\n",
    "        \n",
    "        self.D.add(Conv1D(64, 3, padding='same'))\n",
    "        self.D.add(Activation('elu'))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv1D(64, 3, padding='same'))\n",
    "        self.D.add(Activation('elu'))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        self.D.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten(input_shape=Input_shape))\n",
    "        self.D.add(Dense(512))\n",
    "        self.D.add(Dropout(0.20))\n",
    "        self.D.add(Dense(256))\n",
    "        self.D.add(Dropout(0.20))\n",
    "        self.D.add(Dense(128))\n",
    "        self.D.add(Dropout(0.20))\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        Input_shape = (8,1)\n",
    "        \n",
    "        self.G.add(Conv1D(32, 2, padding='same', input_shape=Input_shape))\n",
    "        self.G.add(Activation('elu'))\n",
    "        self.G.add(Conv1D(32, 2, padding='same'))\n",
    "        self.G.add(Activation('elu'))\n",
    "        self.G.add(AveragePooling1D(pool_size=2))\n",
    "        self.G.add(Dropout(0.2))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(GRU(30, input_shape=Input_shape))\n",
    "        #self.G.add(Flatten())\n",
    "        self.G.add(Dense(200))\n",
    "        self.G.add(Dropout(0.20))\n",
    "        self.G.add(Dense(50))\n",
    "        self.G.add(Dropout(0.20))\n",
    "        self.G.add(Dense(1))\n",
    "        #self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.DM\n",
    "    \n",
    "    def complete_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        X = keras.layers.Input(shape=(8,1))\n",
    "        dm = self.discriminator()\n",
    "        gm = self.generator()\n",
    "        pred = gm(X)\n",
    "        expanded_pred = Reshape((1,1))(pred)\n",
    "        concat = Concatenate(axis=1)([X, expanded_pred])\n",
    "        output = dm(concat)\n",
    "        self.AM = keras.models.Model(inputs=[X], outputs=[output])\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.x_train = X_train\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "        self.complete = self.DCGAN.complete_model()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0, mode=True):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[7, 1])\n",
    "        for i in range(train_steps):\n",
    "            \n",
    "            noise = np.random.uniform(0, 1.0, size=[self.x_train.shape[0], 8,1]) ##########\n",
    "            #print noise\n",
    "            #sequence_fake = self.generator.predict(self.x_train) #########\n",
    "            sequence_fake = self.generator.predict(self.x_train) #########\n",
    "            #print sequence_fake\n",
    "            x_fake = np.concatenate([self.x_train.squeeze(), sequence_fake], axis = 1) ###\n",
    "            y_fake = np.zeros((x_fake.shape[0], 1))\n",
    "            x_real = np.concatenate([self.x_train.squeeze(), y_train], axis=1)\n",
    "            y_real = np.ones((x_fake.shape[0], 1))\n",
    "            if mode==True:\n",
    "                x = np.concatenate([x_fake, x_real])\n",
    "                y = np.concatenate([y_fake, y_real])\n",
    "            else:\n",
    "                x = np.concatenate([x_fake, x_real])\n",
    "                y = np.concatenate([y_real, y_fake])\n",
    "            #print x_fake\n",
    "            d_loss = self.discriminator.train_on_batch(np.expand_dims(x, -1), y)\n",
    "            optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "\n",
    "            for layer in self.discriminator.layers:\n",
    "                layer.trainable = False\n",
    "            self.discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            x = self.x_train\n",
    "            y = np.ones((self.x_train.shape[0], 1))\n",
    "#             print (x)\n",
    "            a_loss = self.complete.train_on_batch(x,y)\n",
    "            \n",
    "            for layer in self.discriminator.layers:\n",
    "                layer.trainable=True\n",
    "            self.discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            #self.discriminator.summary()\n",
    "#             noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "#             a_loss = self.adversarial.train_on_batch(noise.reshape(7,1), y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mnist_dcgan = MNIST_DCGAN()\n",
    "    #timer = ElapsedTimer()\n",
    "    mnist_dcgan.train(train_steps=10, batch_size=256, save_interval=500)\n",
    "    mnist_dcgan.train(train_steps=10, batch_size=256, save_interval=500, mode = False)\n",
    "    #timer.elapsed_time()\n",
    "    #mnist_dcgan.plot_images(fake=True)\n",
    "#mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.5657277]\n",
      " [ 6.52355  ]\n",
      " [ 6.1205153]\n",
      " [ 6.167235 ]\n",
      " [ 6.1100636]\n",
      " [ 5.882875 ]\n",
      " [ 5.5965605]\n",
      " [ 5.632631 ]\n",
      " [ 5.8490343]\n",
      " [ 5.7696314]\n",
      " [ 5.891674 ]\n",
      " [ 5.7994328]\n",
      " [ 6.021728 ]\n",
      " [ 6.1256585]\n",
      " [ 6.014902 ]\n",
      " [ 5.8259044]\n",
      " [ 5.978814 ]\n",
      " [ 6.0923305]\n",
      " [ 6.214637 ]\n",
      " [ 6.300411 ]\n",
      " [ 6.382079 ]\n",
      " [ 6.361119 ]\n",
      " [ 6.463279 ]\n",
      " [ 6.6041436]\n",
      " [ 6.4662037]\n",
      " [ 6.4867864]\n",
      " [ 6.559149 ]\n",
      " [ 6.6271076]\n",
      " [ 6.7069836]\n",
      " [ 6.7005043]\n",
      " [ 6.7926545]\n",
      " [ 6.788913 ]\n",
      " [ 6.965568 ]\n",
      " [ 6.9454966]\n",
      " [ 7.1537266]\n",
      " [ 7.311548 ]\n",
      " [ 7.26346  ]\n",
      " [ 7.4414845]\n",
      " [ 7.49863  ]\n",
      " [ 7.5294714]\n",
      " [ 7.601968 ]\n",
      " [ 7.708296 ]\n",
      " [ 7.529887 ]\n",
      " [ 7.248274 ]\n",
      " [ 7.2037706]\n",
      " [ 7.237572 ]\n",
      " [ 7.2818956]\n",
      " [ 7.4135113]\n",
      " [ 7.359506 ]\n",
      " [ 7.401603 ]\n",
      " [ 7.3762717]\n",
      " [ 7.185521 ]\n",
      " [ 7.047817 ]\n",
      " [ 6.893516 ]\n",
      " [ 6.952689 ]\n",
      " [ 6.961903 ]\n",
      " [ 6.831615 ]\n",
      " [ 6.742798 ]\n",
      " [ 6.8746486]\n",
      " [ 6.9294543]\n",
      " [ 6.9735255]\n",
      " [ 6.776651 ]\n",
      " [ 6.768881 ]\n",
      " [ 6.894238 ]\n",
      " [ 7.1464562]\n",
      " [ 7.2040443]\n",
      " [ 7.586762 ]\n",
      " [ 7.6884394]\n",
      " [ 7.699392 ]\n",
      " [ 7.536943 ]\n",
      " [ 7.4536033]\n",
      " [ 7.54844  ]\n",
      " [ 7.60153  ]\n",
      " [ 7.667552 ]\n",
      " [ 7.7176833]\n",
      " [ 7.651521 ]\n",
      " [ 7.723091 ]\n",
      " [ 7.6759553]\n",
      " [ 7.549521 ]\n",
      " [ 7.4147525]\n",
      " [ 7.505483 ]\n",
      " [ 7.452022 ]\n",
      " [ 7.171007 ]\n",
      " [ 7.2187085]\n",
      " [ 7.1813836]\n",
      " [ 7.1344376]\n",
      " [ 7.106153 ]\n",
      " [ 6.9523444]\n",
      " [ 7.0534315]\n",
      " [ 7.295242 ]\n",
      " [ 7.6651635]\n",
      " [ 7.4742227]\n",
      " [ 7.227025 ]\n",
      " [ 7.1706085]\n",
      " [ 7.17771  ]\n",
      " [ 7.22421  ]\n",
      " [ 7.0871425]\n",
      " [ 7.320915 ]\n",
      " [ 7.520387 ]\n",
      " [ 7.5722656]\n",
      " [ 7.6395197]\n",
      " [ 7.498904 ]\n",
      " [ 7.7319694]\n",
      " [ 7.747274 ]\n",
      " [ 7.915818 ]\n",
      " [ 7.7623386]\n",
      " [ 7.4684067]\n",
      " [ 7.6176467]\n",
      " [ 7.6454215]\n",
      " [ 7.69483  ]\n",
      " [ 7.67126  ]\n",
      " [ 7.848962 ]\n",
      " [ 7.813761 ]\n",
      " [ 7.672532 ]\n",
      " [ 7.6381845]\n",
      " [ 7.644579 ]\n",
      " [ 7.6562266]\n",
      " [ 7.473857 ]\n",
      " [ 7.3946247]\n",
      " [ 7.409019 ]\n",
      " [ 7.5080633]\n",
      " [ 7.526592 ]\n",
      " [ 7.7530746]\n",
      " [ 7.8640428]\n",
      " [ 8.027744 ]\n",
      " [ 8.066617 ]\n",
      " [ 8.1944275]\n",
      " [ 8.436345 ]\n",
      " [ 8.49934  ]\n",
      " [ 8.291573 ]\n",
      " [ 8.072717 ]\n",
      " [ 7.9488344]\n",
      " [ 7.976419 ]\n",
      " [ 8.114991 ]\n",
      " [ 8.242612 ]\n",
      " [ 8.236502 ]\n",
      " [ 8.366762 ]\n",
      " [ 8.363675 ]\n",
      " [ 8.5337925]\n",
      " [ 8.685676 ]\n",
      " [ 8.72875  ]\n",
      " [ 8.898703 ]\n",
      " [ 8.795651 ]\n",
      " [ 8.719824 ]\n",
      " [ 8.659462 ]\n",
      " [ 8.77956  ]\n",
      " [ 9.05251  ]\n",
      " [ 9.299994 ]\n",
      " [ 9.127765 ]\n",
      " [ 9.148565 ]\n",
      " [ 9.166862 ]\n",
      " [ 9.228336 ]\n",
      " [ 9.368867 ]\n",
      " [ 9.232048 ]\n",
      " [ 9.252262 ]\n",
      " [ 9.097019 ]\n",
      " [ 9.038936 ]\n",
      " [ 9.219048 ]\n",
      " [ 9.218629 ]\n",
      " [ 9.145571 ]\n",
      " [ 9.179893 ]\n",
      " [ 9.918212 ]\n",
      " [ 9.903855 ]\n",
      " [ 9.944088 ]\n",
      " [10.081861 ]\n",
      " [10.165414 ]\n",
      " [10.335582 ]\n",
      " [10.44208  ]\n",
      " [10.565686 ]\n",
      " [10.506868 ]\n",
      " [10.68012  ]\n",
      " [10.856315 ]\n",
      " [10.882499 ]\n",
      " [10.793501 ]\n",
      " [10.471371 ]\n",
      " [10.362157 ]\n",
      " [10.255854 ]\n",
      " [10.151125 ]\n",
      " [10.127353 ]\n",
      " [10.424667 ]\n",
      " [10.459992 ]\n",
      " [10.409946 ]\n",
      " [10.658796 ]\n",
      " [10.682108 ]\n",
      " [10.8114   ]\n",
      " [10.629929 ]\n",
      " [10.61763  ]\n",
      " [10.7041   ]\n",
      " [10.745402 ]\n",
      " [10.75529  ]\n",
      " [10.679229 ]\n",
      " [10.468245 ]\n",
      " [10.223303 ]\n",
      " [10.4343405]\n",
      " [10.379577 ]\n",
      " [10.285088 ]\n",
      " [10.166941 ]\n",
      " [ 9.955018 ]\n",
      " [10.153546 ]\n",
      " [ 9.839821 ]\n",
      " [10.086812 ]\n",
      " [10.115459 ]\n",
      " [10.259954 ]\n",
      " [10.446073 ]\n",
      " [10.432933 ]\n",
      " [10.488937 ]\n",
      " [10.296105 ]\n",
      " [10.225716 ]\n",
      " [10.428474 ]\n",
      " [10.265453 ]\n",
      " [10.318764 ]\n",
      " [10.335726 ]\n",
      " [10.281021 ]\n",
      " [10.394507 ]\n",
      " [10.263014 ]\n",
      " [11.133689 ]\n",
      " [11.420399 ]\n",
      " [11.490843 ]\n",
      " [11.52987  ]\n",
      " [11.240773 ]\n",
      " [11.310276 ]\n",
      " [11.316678 ]\n",
      " [11.376571 ]\n",
      " [11.650827 ]\n",
      " [11.982845 ]\n",
      " [12.245615 ]\n",
      " [12.278612 ]\n",
      " [12.386259 ]\n",
      " [12.292328 ]\n",
      " [12.364297 ]\n",
      " [12.210238 ]\n",
      " [11.951416 ]\n",
      " [12.260789 ]\n",
      " [11.81452  ]\n",
      " [11.960435 ]\n",
      " [11.957158 ]\n",
      " [12.211923 ]\n",
      " [12.293663 ]\n",
      " [12.293155 ]\n",
      " [12.346879 ]\n",
      " [11.857309 ]\n",
      " [12.006548 ]\n",
      " [12.010969 ]\n",
      " [12.0916815]\n",
      " [11.914849 ]\n",
      " [11.716317 ]\n",
      " [11.948193 ]\n",
      " [12.233679 ]\n",
      " [12.557644 ]\n",
      " [12.666684 ]\n",
      " [12.578018 ]\n",
      " [12.628745 ]\n",
      " [12.5928135]\n",
      " [12.678731 ]\n",
      " [12.687231 ]\n",
      " [12.82243  ]\n",
      " [12.620862 ]\n",
      " [12.437343 ]\n",
      " [12.472643 ]\n",
      " [12.473192 ]\n",
      " [12.735268 ]\n",
      " [12.654654 ]\n",
      " [12.851517 ]\n",
      " [13.010888 ]\n",
      " [12.812305 ]\n",
      " [12.95833  ]\n",
      " [13.03887  ]\n",
      " [13.118639 ]\n",
      " [13.026406 ]\n",
      " [13.03695  ]\n",
      " [13.014169 ]\n",
      " [13.385268 ]\n",
      " [13.848087 ]\n",
      " [13.872236 ]\n",
      " [14.13061  ]\n",
      " [14.01998  ]\n",
      " [14.013748 ]\n",
      " [13.701959 ]\n",
      " [14.047763 ]\n",
      " [13.909377 ]\n",
      " [13.730592 ]\n",
      " [13.690682 ]\n",
      " [13.779921 ]\n",
      " [13.78135  ]\n",
      " [13.741955 ]\n",
      " [14.040584 ]\n",
      " [14.256838 ]\n",
      " [14.28173  ]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions\n",
    "trainPredict = mnist_dcgan.generator.predict(X_train)\n",
    "testPredict =mnist_dcgan.generator.predict(X_test)\n",
    "\n",
    "print (testPredict)\n",
    "\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(y_train)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(y_test)\n",
    "#print(testPredict[400:],'\\n\\n\\n\\n',testY[400:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Difference: 5860.96 \n",
      "Average Testing Difference: 10076.86 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e77706f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainScore=0\n",
    "testScore=0\n",
    "# calculate root mean squared error\n",
    "for i in range (trainY.shape[0]):\n",
    "    trainScore += math.sqrt(mean_squared_error(trainY[i], trainPredict[i]))\n",
    "trainScore=trainScore/trainY.shape[0]\n",
    "\n",
    "for i in range (testY.shape[0]):\n",
    "    testScore += math.sqrt(mean_squared_error(testY[i],testPredict[i]))\n",
    "testScore=testScore/testY.shape[0]\n",
    "\n",
    "print('Average Training Difference: %.2f ' % (trainScore))\n",
    "print('Average Testing Difference: %.2f ' % (testScore))\n",
    "# for i in range(testPredict.shape[0]):\n",
    "#     if testPredict[i] > 1000:\n",
    "#         print testPredict[i]\n",
    "plt.plot(testPredict)\n",
    "\n",
    "plt.plot(testY)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
